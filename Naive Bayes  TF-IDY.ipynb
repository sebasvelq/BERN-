{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb9f51-0768-4879-a33b-19a4ac623dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV en un DataFrame\n",
    "df_data = pd.read_csv('complaints.csv')\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame para verificar el contenido\n",
    "print(df_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd457b-45aa-4d2d-a47e-d2eae6b7deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_data.dropna(subset=['Consumer complaint narrative'])\n",
    "# Mostrar las filas con texto en 'Consumer complaint narrative'\n",
    "textual_data = df_data[df_data['Consumer complaint narrative'].notna()]\n",
    "df_filtered_1 = df_filtered.sample(n=5000, random_state=42)\n",
    "\n",
    "# Mostrar las primeras filas de esa columna con texto\n",
    "print(\"\\nAlgunas filas de 'Consumer complaint narrative' con texto:\")\n",
    "print(textual_data['Consumer complaint narrative'].head())\n",
    "\n",
    "# Contar el total de filas con texto y el total de filas del DataFrame\n",
    "num_texts = df_filtered_1.shape[0]\n",
    "total_rows = df_data.shape[0]\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f\"\\nNúmero de filas con texto en 'Consumer complaint narrative': {num_texts}\")\n",
    "print(f\"Total de filas en el DataFrame: {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbb625c-0481-460c-b405-978b59b2b310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "import nltk\n",
    "# Descargar recursos necesarios para nltk \n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Función para preprocesar el texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuación\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenizar el texto\n",
    "    tokens = word_tokenize(text)\n",
    "    # Eliminar stopwords en inglés \n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    # Lematizar \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Calcular el número de instancias por clase\n",
    "class_counts = df_filtered_1['Product'].value_counts()\n",
    "\n",
    "# Definir un umbral mínimo de instancias por clase \n",
    "min_samples = 200\n",
    "\n",
    "# Filtrar las filas cuyo 'Product' tenga al menos el número mínimo de instancias\n",
    "df_filtered_1 = df_filtered_1[df_filtered_1['Product'].isin(class_counts[class_counts >= min_samples].index)]\n",
    "\n",
    "\n",
    "# Aplicar el preprocesamiento a la columna 'Consumer complaint narrative'\n",
    "df_filtered_1['processed_text'] = df_filtered_1['Consumer complaint narrative'].apply(preprocess_text)\n",
    "\n",
    "# Mostrar algunas filas del texto \n",
    "print(df_filtered_1[['Consumer complaint narrative', 'processed_text']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfe6f7c-279a-406b-8009-928bbfb5e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Inicializar el vectorizador TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))  # Ejemplo con bigramas\n",
    "\n",
    "\n",
    "# Ajustar y transformar los textos procesados\n",
    "X = df_filtered_1['processed_text']\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Mostrar el tamaño de la matriz TF-IDF\n",
    "print(f\"Tamaño del vector TF-IDF: {X_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7917dea-5c12-4be5-a353-a9c1fd07696a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extraer las características y etiquetas después de filtrar\n",
    "X = df_filtered_1['processed_text']\n",
    "y = df_filtered_1['Product']\n",
    "\n",
    "# Volver a vectorizar con TF-IDF\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8228153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Inicializar el modelo Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Entrenar el modelo\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c396712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Obtener los totales por categoría en el conjunto completo\n",
    "total_por_categoria = df_filtered_1['Product'].value_counts()\n",
    "\n",
    "# 2. Obtener la cantidad de datos por categoría en el conjunto de entrenamiento\n",
    "entrenamiento_por_categoria = y_train.value_counts()\n",
    "\n",
    "# 3. Obtener la cantidad de datos por categoría en el conjunto de prueba\n",
    "prueba_por_categoria = y_test.value_counts()\n",
    "\n",
    "# 4. Obtener la cantidad de predicciones exitosas (correctas) en el conjunto de prueba\n",
    "aciertos = y_test[y_test == y_pred]\n",
    "aciertos_por_categoria = aciertos.value_counts()\n",
    "\n",
    "# 5. Combinar toda la información en un solo DataFrame\n",
    "resultados = pd.DataFrame({\n",
    "    'Total': total_por_categoria,\n",
    "    'Entrenamiento': entrenamiento_por_categoria,\n",
    "    'Prueba': prueba_por_categoria,\n",
    "    'Aciertos en prueba': aciertos_por_categoria\n",
    "})\n",
    "\n",
    "# Reemplazar los NaN por 0\n",
    "resultados = resultados.fillna(0).astype(int)\n",
    "\n",
    "# Mostrar la tabla resultante\n",
    "print(resultados)\n",
    "\n",
    "# Si prefieres guardar los resultados en un archivo CSV:\n",
    "#resultados.to_csv('resultados_por_categoria.csv', index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5032daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Crear etiquetas simplificadas\n",
    "etiquetas_simplificadas = [f\"Categoría {i+1}\" for i in range(len(total_por_categoria))]\n",
    "\n",
    "# Crear la tabla de correspondencia\n",
    "tabla_correspondencia = pd.DataFrame({\n",
    "    \"Categoría Simplificada\": etiquetas_simplificadas,\n",
    "    \"Texto Original\": total_por_categoria.index  # Guardamos los nombres largos originales aquí\n",
    "})\n",
    "\n",
    "# Crear el gráfico de barras con etiquetas simplificadas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(etiquetas_simplificadas, total_por_categoria.values, color='skyblue')\n",
    "plt.title(\"Distribución de Clases en el Dataset Completo\")\n",
    "plt.xlabel(\"Categoría de Producto\")\n",
    "plt.ylabel(\"Número de Quejas\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar la tabla de correspondencia debajo del gráfico\n",
    "print(tabla_correspondencia)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe539736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Crear etiquetas simplificadas para cada gráfico\n",
    "etiquetas_simplificadas_entrenamiento = [f\"Categoría {i+1}\" for i in range(len(entrenamiento_por_categoria))]\n",
    "etiquetas_simplificadas_prueba = [f\"Categoría {i+1}\" for i in range(len(prueba_por_categoria))]\n",
    "\n",
    "# Crear tablas de correspondencia para ambos conjuntos\n",
    "tabla_correspondencia_entrenamiento = pd.DataFrame({\n",
    "    \"Categoría Simplificada\": etiquetas_simplificadas_entrenamiento,\n",
    "    \"Texto Original\": entrenamiento_por_categoria.index  # Usamos el índice original aquí\n",
    "})\n",
    "\n",
    "tabla_correspondencia_prueba = pd.DataFrame({\n",
    "    \"Categoría Simplificada\": etiquetas_simplificadas_prueba,\n",
    "    \"Texto Original\": prueba_por_categoria.index  # Usamos el índice original aquí\n",
    "})\n",
    "\n",
    "# Crear gráficos de barras con etiquetas simplificadas\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Gráfico para el conjunto de entrenamiento\n",
    "ax[0].bar(etiquetas_simplificadas_entrenamiento, entrenamiento_por_categoria.values, color='lightgreen')\n",
    "ax[0].set_title(\"Distribución en Entrenamiento\")\n",
    "ax[0].set_xlabel(\"Categoría de Producto\")\n",
    "ax[0].set_ylabel(\"Número de Quejas\")\n",
    "ax[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Gráfico para el conjunto de prueba\n",
    "ax[1].bar(etiquetas_simplificadas_prueba, prueba_por_categoria.values, color='lightcoral')\n",
    "ax[1].set_title(\"Distribución en Prueba\")\n",
    "ax[1].set_xlabel(\"Categoría de Producto\")\n",
    "ax[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar tablas de correspondencia para ambos conjuntos\n",
    "print(\"Tabla de correspondencia para Entrenamiento:\")\n",
    "print(tabla_correspondencia_entrenamiento)\n",
    "print(\"\\nTabla de correspondencia para Prueba:\")\n",
    "print(tabla_correspondencia_prueba)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e70f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Crear etiquetas simplificadas\n",
    "etiquetas_simplificadas = [f\"Categoría {i+1}\" for i in range(len(nb_model.classes_))]\n",
    "\n",
    "# Crear tabla de correspondencia para etiquetas originales y simplificadas\n",
    "tabla_correspondencia = pd.DataFrame({\n",
    "    \"Categoría Simplificada\": etiquetas_simplificadas,\n",
    "    \"Etiqueta Original\": nb_model.classes_\n",
    "})\n",
    "\n",
    "# Crear la matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred, labels=nb_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=etiquetas_simplificadas)\n",
    "\n",
    "# Visualizar la matriz de confusión con etiquetas simplificadas\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "disp.plot(cmap=\"Blues\", ax=ax)\n",
    "plt.title(\"Matriz de Confusión para el Modelo Naive Bayes\")\n",
    "plt.show()\n",
    "\n",
    "# Mostrar la tabla de correspondencia\n",
    "print(\"Tabla de correspondencia de etiquetas:\")\n",
    "print(tabla_correspondencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c18a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Crear una serie de errores por categoría\n",
    "errores_por_categoria = y_test[y_test != y_pred].value_counts()\n",
    "\n",
    "# Crear etiquetas simplificadas para las categorías con errores\n",
    "etiquetas_simplificadas = [f\"Categoría {i+1}\" for i in range(len(errores_por_categoria))]\n",
    "tabla_correspondencia = pd.DataFrame({\n",
    "    \"Categoría Simplificada\": etiquetas_simplificadas,\n",
    "    \"Etiqueta Original\": errores_por_categoria.index  # Guardamos los nombres largos originales aquí\n",
    "})\n",
    "\n",
    "# Visualizar errores por categoría con etiquetas simplificadas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(etiquetas_simplificadas, errores_por_categoria.values, color='salmon')\n",
    "plt.title(\"Distribución de Errores por Categoría\")\n",
    "plt.xlabel(\"Categoría\")\n",
    "plt.ylabel(\"Número de Errores\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Mostrar la tabla de correspondencia debajo del gráfico\n",
    "print(\"Tabla de correspondencia de errores por categoría:\")\n",
    "print(tabla_correspondencia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_1['text_length'] = df_filtered_1['Consumer complaint narrative'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Histograma de la longitud de textos\n",
    "plt.hist(df_filtered_1['text_length'], bins=30, color='purple', edgecolor='black')\n",
    "plt.title(\"Distribución de la Longitud de las Quejas\")\n",
    "plt.xlabel(\"Número de Palabras\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1743376a-b5c5-4664-a7b6-8f8e510f12d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
